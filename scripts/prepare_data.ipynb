{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/jiazhi/Workshop/common-voice-zh-tw/scripts/dict.txt.big ...\n",
      "Dumping model to file cache /tmp/jieba.ufe63d437a4894b8c7d3a0a0158031718.cache\n",
      "Loading model cost 1.014 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from bopomofo.main import trans_sentense\n",
    "\n",
    "import jieba\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "jieba.initialize()\n",
    "\n",
    "DATA_DIR = '/home/jiazhi/Dataset/common-voice_zh-TW_43h_2019-06-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaldi_gender(gender):\n",
    "    ''' Alter CommonVoice gender into kaldi format. '''\n",
    "    if gender == 'male':\n",
    "        return 'm'\n",
    "    elif gender == 'female':\n",
    "        return 'f'\n",
    "    else:\n",
    "        return 'm'\n",
    "    \n",
    "def path2utt(row):\n",
    "    ''' Convert audio path into utterance id. '''\n",
    "    utt_id = row.path[:-4].split('_')[-1]\n",
    "    prefix = row.spk_id\n",
    "    return f'{prefix}_{utt_id}'\n",
    "\n",
    "def is_chinese(char):\n",
    "    ''' Check if character is chinese. '''\n",
    "    return u'\\u4e00' <= char <= u'\\u9fff'\n",
    "\n",
    "def fix_char(sent):\n",
    "    ''' Fix unusual chinese characters. '''\n",
    "    sent = sent.replace('内', '內')\n",
    "    sent = sent.replace('爲', '為')\n",
    "    sent = sent.replace('柺', '拐')\n",
    "    sent = sent.replace('庄', '莊')\n",
    "    sent = sent.replace('麽', '麼')\n",
    "    sent = sent.replace('污', '汙')\n",
    "    sent = sent.replace('値', '值')\n",
    "    return sent\n",
    "    \n",
    "def jieba_cut(sent):\n",
    "    ''' Chinese segmentation with punctuations removed. '''\n",
    "    return [c for c in jieba.cut(sent) if is_chinese(c)]\n",
    "\n",
    "def contains_no_eng(text):\n",
    "    ''' Check if text contains no english. '''\n",
    "    for char in text:\n",
    "        if 'a' <= char <= 'z' or \\\n",
    "           'A' <= char <= 'Z' or \\\n",
    "           u'\\uff21' <= char <= u'\\uff3a' or \\\n",
    "           u'\\uff41' <= char <= u'\\uff5a':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def zhuyin2phones(zhuyin, use_tone=True):\n",
    "    ''' Convert zhuyin of a charcter to phonemes. '''\n",
    "    if zhuyin[0] == u'\\u02d9':  # Neutral(fifth) tone \n",
    "        phones = ' '.join([c for c in zhuyin][1:])\n",
    "        tone = zhuyin[0]\n",
    "    else:\n",
    "        phones = ' '.join([c for c in zhuyin][:-1])\n",
    "        tone = zhuyin[-1]\n",
    "    if use_tone:\n",
    "        phones = f'{phones}{tone}'\n",
    "    return phones\n",
    "\n",
    "def fix_phones(phones):\n",
    "    ''' Fix broken phonemes. '''\n",
    "    phones = phones.replace('一', 'ㄧ')\n",
    "    phones = phones.replace('勳', 'ㄒ ㄩ ㄣ-')\n",
    "    phones = phones.replace('艷', 'ㄧ ㄢˋ')\n",
    "    phones = phones.replace('曬', 'ㄕ ㄞˋ')\n",
    "    return phones\n",
    "\n",
    "def word2phones(word):\n",
    "    ''' Convert a chinese word to zhuyin phonemes. '''\n",
    "    zhuyins = trans_sentense(word).split()\n",
    "    phones = ' '.join([zhuyin2phones(z) for z in zhuyins])\n",
    "    phones = fix_phones(phones)\n",
    "    return phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structures\n",
    "try:\n",
    "    os.mkdir('../data')\n",
    "    os.mkdir('../data/train')\n",
    "    os.mkdir('../data/test')\n",
    "    os.mkdir('../data/local')\n",
    "    os.mkdir('../data/local/dict')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and merge information of train/test set\n",
    "train_tsv = join(DATA_DIR, 'train.tsv')\n",
    "test_tsv = join(DATA_DIR, 'test.tsv')\n",
    "train_df = pd.read_csv(train_tsv, sep='\\t')\n",
    "test_df = pd.read_csv(test_tsv, sep='\\t')\n",
    "\n",
    "# Exclude audios with english\n",
    "train_df = train_df[train_df.sentence.apply(contains_no_eng)]\n",
    "test_df = test_df[test_df.sentence.apply(contains_no_eng)]\n",
    "full_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape: (1697, 8)\n",
      "test_df.shape:  (1535, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...</td>\n",
       "      <td>common_voice_zh-TW_17377831.mp3</td>\n",
       "      <td>我們特別回鄉下</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...</td>\n",
       "      <td>common_voice_zh-TW_17377841.mp3</td>\n",
       "      <td>是歷史上的第二次</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...</td>\n",
       "      <td>common_voice_zh-TW_17377844.mp3</td>\n",
       "      <td>簡單來說</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...</td>\n",
       "      <td>common_voice_zh-TW_17377846.mp3</td>\n",
       "      <td>在田裡也需幫忙</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...</td>\n",
       "      <td>common_voice_zh-TW_17377848.mp3</td>\n",
       "      <td>婚後一年生了個女嬰</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...   \n",
       "1  729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...   \n",
       "2  729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...   \n",
       "3  729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...   \n",
       "4  729aa31a7cb19fbf96fb390f0e7e74dd408a2579ce811a...   \n",
       "\n",
       "                              path   sentence  up_votes  down_votes       age  \\\n",
       "0  common_voice_zh-TW_17377831.mp3    我們特別回鄉下         2           0  thirties   \n",
       "1  common_voice_zh-TW_17377841.mp3   是歷史上的第二次         2           0  thirties   \n",
       "2  common_voice_zh-TW_17377844.mp3       簡單來說         2           1  thirties   \n",
       "3  common_voice_zh-TW_17377846.mp3    在田裡也需幫忙         2           0  thirties   \n",
       "4  common_voice_zh-TW_17377848.mp3  婚後一年生了個女嬰         2           1  thirties   \n",
       "\n",
       "  gender accent  \n",
       "0   male    NaN  \n",
       "1   male    NaN  \n",
       "2   male    NaN  \n",
       "3   male    NaN  \n",
       "4   male    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'train_df.shape: {train_df.shape}')\n",
    "print(f'test_df.shape:  {test_df.shape}')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare spk_id, gender and utt_id for all audios\n",
    "client_spk = full_df[['client_id']].drop_duplicates()\n",
    "client_spk['spk_id'] = range(1, 1 + len(client_spk))\n",
    "client_spk.spk_id = client_spk.spk_id.apply(lambda x: str(x).zfill(3))\n",
    "full_df = full_df.merge(client_spk)\n",
    "full_df.gender = full_df.gender.apply(kaldi_gender)\n",
    "full_df['utt_id'] = full_df.apply(path2utt, axis=1)\n",
    "\n",
    "# Fix unusual character and do text segmentation\n",
    "full_df.sentence = full_df.sentence.apply(fix_char)\n",
    "full_df.sentence = full_df.sentence.apply(jieba_cut)\n",
    "\n",
    "# Drop useless columns\n",
    "drop_columns = ['client_id', 'up_votes', 'down_votes', 'age', 'accent']\n",
    "full_df.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "# Split processed dataset to train/test set\n",
    "train_df = full_df[:-len(test_df)]\n",
    "test_df = full_df[-len(test_df):]\n",
    "\n",
    "# Sort train/test set by utt_id for kaldi-mfcc\n",
    "train_df = train_df.sort_values(by='utt_id')\n",
    "test_df = test_df.sort_values(by='utt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape: (1697, 5)\n",
      "test_df.shape:  (1535, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>gender</th>\n",
       "      <th>spk_id</th>\n",
       "      <th>utt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_zh-TW_17377831.mp3</td>\n",
       "      <td>[我們, 特別, 回鄉, 下]</td>\n",
       "      <td>m</td>\n",
       "      <td>001</td>\n",
       "      <td>001_17377831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_zh-TW_17377841.mp3</td>\n",
       "      <td>[是, 歷史, 上, 的, 第二次]</td>\n",
       "      <td>m</td>\n",
       "      <td>001</td>\n",
       "      <td>001_17377841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_zh-TW_17377844.mp3</td>\n",
       "      <td>[簡單, 來說]</td>\n",
       "      <td>m</td>\n",
       "      <td>001</td>\n",
       "      <td>001_17377844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_zh-TW_17377846.mp3</td>\n",
       "      <td>[在, 田裡, 也, 需, 幫忙]</td>\n",
       "      <td>m</td>\n",
       "      <td>001</td>\n",
       "      <td>001_17377846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_zh-TW_17377848.mp3</td>\n",
       "      <td>[婚後, 一年生, 了, 個, 女嬰]</td>\n",
       "      <td>m</td>\n",
       "      <td>001</td>\n",
       "      <td>001_17377848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path             sentence gender spk_id  \\\n",
       "0  common_voice_zh-TW_17377831.mp3      [我們, 特別, 回鄉, 下]      m    001   \n",
       "1  common_voice_zh-TW_17377841.mp3   [是, 歷史, 上, 的, 第二次]      m    001   \n",
       "2  common_voice_zh-TW_17377844.mp3             [簡單, 來說]      m    001   \n",
       "3  common_voice_zh-TW_17377846.mp3    [在, 田裡, 也, 需, 幫忙]      m    001   \n",
       "4  common_voice_zh-TW_17377848.mp3  [婚後, 一年生, 了, 個, 女嬰]      m    001   \n",
       "\n",
       "         utt_id  \n",
       "0  001_17377831  \n",
       "1  001_17377841  \n",
       "2  001_17377844  \n",
       "3  001_17377846  \n",
       "4  001_17377848  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'train_df.shape: {train_df.shape}')\n",
    "print(f'test_df.shape:  {test_df.shape}')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write files for kaldi usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write acoustic data of train/test set\n",
    "for split, df in zip(['train', 'test'], [train_df, test_df]):\n",
    "    \n",
    "    # spk2gender\n",
    "    spk2gender = df[['spk_id', 'gender']].drop_duplicates()\n",
    "    spk2gender = spk2gender.sort_values(by='spk_id')\n",
    "    with open(join('../data', split, 'spk2gender'), 'w', encoding='UTF-8') as f:\n",
    "        for _, row in spk2gender.iterrows():\n",
    "            f.write(f'{row.spk_id} {row.gender}\\n')\n",
    "            \n",
    "    # wav.scp\n",
    "    with open(join('../data', split, 'wav.scp'), 'w', encoding='UTF-8') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            mp3_path = join(DATA_DIR, 'clips', row.path)\n",
    "            f.write(f'{row.utt_id} sox {mp3_path} -t wav - |\\n')\n",
    "    \n",
    "    # text\n",
    "    with open(join('../data', split, 'text'), 'w', encoding='UTF-8') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            text = ' '.join(row.sentence)\n",
    "            f.write(f'{row.utt_id} {text}\\n')\n",
    "            \n",
    "    # utt2spk\n",
    "    with open(join('../data', split, 'utt2spk'), 'w', encoding='UTF-8') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(f'{row.utt_id} {row.spk_id}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus.txt\n",
    "corpus = full_df.sentence.apply(' '.join).tolist()\n",
    "with open('../data/local/corpus.txt', 'w', encoding='UTF-8') as f:\n",
    "    for sent in corpus:\n",
    "        f.write(f'{sent}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon.txt\n",
    "phone_set = []\n",
    "with open('../data/local/dict/lexicon.txt', 'w', encoding='UTF-8') as f:\n",
    "    f.write('!SIL sil\\n')\n",
    "    f.write('<UNK> spn\\n')\n",
    "    for word in set(w for s in full_df.sentence.tolist() for w in s):\n",
    "        phones = word2phones(word)\n",
    "        phone_set += phones.split()\n",
    "        f.write(f'{word} {phones}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phone files\n",
    "phone_set = set(phone_set)\n",
    "with open('../data/local/dict/nonsilence_phones.txt', 'w', encoding='UTF-8') as f:\n",
    "    for phone in phone_set:\n",
    "        f.write(f'{phone}\\n')\n",
    "        \n",
    "with open('../data/local/dict/silence_phones.txt', 'w', encoding='UTF-8') as f:\n",
    "    f.write('sil\\nspn')\n",
    "    \n",
    "with open('../data/local/dict/optional_silence.txt', 'w', encoding='UTF-8') as f:\n",
    "    f.write('sil')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
