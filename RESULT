
===== PREPARING REQUIRED DATA =====

Preparing AM data...Preparing AM data... DONE
Preparing LM data...Preparing LM data... DONE
Program `prepare_data.py` ends succesfully.

===== PREPARING ACOUSTIC DATA =====


===== FEATURES EXTRACTION =====

steps/make_mfcc.sh --nj 4 --cmd run.pl data/train exp/make_mfcc/train mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for train
steps/make_mfcc.sh --nj 4 --cmd run.pl data/test exp/make_mfcc/test mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/test
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for test
steps/compute_cmvn_stats.sh data/train exp/make_mfcc/train mfcc
Succeeded creating CMVN stats for train
steps/compute_cmvn_stats.sh data/test exp/make_mfcc/test mfcc
Succeeded creating CMVN stats for test

===== PREPARING LANGUAGE DATA =====

utils/prepare_lang.sh data/local/dict <UNK> data/local/lang data/lang
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

**Creating data/local/dict/lexiconp.txt from data/local/dict/lexicon.txt
prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 148 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 13 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 39 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 39 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 158 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 82 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 100 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]

===== LANGUAGE MODEL CREATION =====
===== MAKING lm.arpa =====


===== MAKING G.fst =====


===== MONO TRAINING =====

steps/train_mono.sh --nj 4 --cmd run.pl data/train data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/mono
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log
36 warnings in exp/mono/log/acc.*.*.log
200 warnings in exp/mono/log/update.*.log
662 warnings in exp/mono/log/align.*.*.log
exp/mono: nj=4 align prob=-94.32 over 1.47h [retry=0.2%, fail=0.1%] states=121 gauss=993
steps/train_mono.sh: Done training monophone system in exp/mono

===== MONO DECODING =====

WARNING: the --mono, --left-biphone and --quinphone options are now deprecated and ignored.
-0.0312146 -0.0321367
[info]: LG not stochastic.
-0.0312146 -0.0321367
[info]: CLG not stochastic.
0.00019061 -0.0618943
HCLGa is not stochastic
steps/decode.sh --config conf/decode.config --nj 4 --cmd run.pl exp/mono/graph data/test exp/mono/decode
decode.sh: feature type is delta
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph exp/mono/decode
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,6,132) and mean=48.8
steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode/log/analyze_lattice_depth_stats.log
exp/mono/decode/wer_10
%WER 31.69 [ 2238 / 7063, 307 ins, 453 del, 1478 sub ]
%SER 52.18 [ 801 / 1535 ]
exp/mono/decode/wer_11
%WER 29.97 [ 2117 / 7063, 247 ins, 471 del, 1399 sub ]
%SER 49.25 [ 756 / 1535 ]
exp/mono/decode/wer_12
%WER 28.84 [ 2037 / 7063, 221 ins, 507 del, 1309 sub ]
%SER 47.23 [ 725 / 1535 ]
exp/mono/decode/wer_13
%WER 27.71 [ 1957 / 7063, 191 ins, 527 del, 1239 sub ]
%SER 45.47 [ 698 / 1535 ]
exp/mono/decode/wer_14
%WER 27.47 [ 1940 / 7063, 176 ins, 546 del, 1218 sub ]
%SER 44.63 [ 685 / 1535 ]
exp/mono/decode/wer_15
%WER 27.18 [ 1920 / 7063, 159 ins, 580 del, 1181 sub ]
%SER 43.78 [ 672 / 1535 ]
exp/mono/decode/wer_16
%WER 27.33 [ 1930 / 7063, 143 ins, 628 del, 1159 sub ]
%SER 43.39 [ 666 / 1535 ]
exp/mono/decode/wer_17
%WER 27.38 [ 1934 / 7063, 130 ins, 661 del, 1143 sub ]
%SER 42.87 [ 658 / 1535 ]
exp/mono/decode/wer_7
%WER 38.96 [ 2752 / 7063, 524 ins, 364 del, 1864 sub ]
%SER 63.06 [ 968 / 1535 ]
exp/mono/decode/wer_8
%WER 35.78 [ 2527 / 7063, 435 ins, 382 del, 1710 sub ]
%SER 58.31 [ 895 / 1535 ]
exp/mono/decode/wer_9
%WER 33.41 [ 2360 / 7063, 368 ins, 404 del, 1588 sub ]
%SER 54.59 [ 838 / 1535 ]
exp/mono/decode//wer_10
%WER 31.69 [ 2238 / 7063, 307 ins, 453 del, 1478 sub ]
%SER 52.18 [ 801 / 1535 ]
exp/mono/decode//wer_11
%WER 29.97 [ 2117 / 7063, 247 ins, 471 del, 1399 sub ]
%SER 49.25 [ 756 / 1535 ]
exp/mono/decode//wer_12
%WER 28.84 [ 2037 / 7063, 221 ins, 507 del, 1309 sub ]
%SER 47.23 [ 725 / 1535 ]
exp/mono/decode//wer_13
%WER 27.71 [ 1957 / 7063, 191 ins, 527 del, 1239 sub ]
%SER 45.47 [ 698 / 1535 ]
exp/mono/decode//wer_14
%WER 27.47 [ 1940 / 7063, 176 ins, 546 del, 1218 sub ]
%SER 44.63 [ 685 / 1535 ]
exp/mono/decode//wer_15
%WER 27.18 [ 1920 / 7063, 159 ins, 580 del, 1181 sub ]
%SER 43.78 [ 672 / 1535 ]
exp/mono/decode//wer_16
%WER 27.33 [ 1930 / 7063, 143 ins, 628 del, 1159 sub ]
%SER 43.39 [ 666 / 1535 ]
exp/mono/decode//wer_17
%WER 27.38 [ 1934 / 7063, 130 ins, 661 del, 1143 sub ]
%SER 42.87 [ 658 / 1535 ]
exp/mono/decode//wer_7
%WER 38.96 [ 2752 / 7063, 524 ins, 364 del, 1864 sub ]
%SER 63.06 [ 968 / 1535 ]
exp/mono/decode//wer_8
%WER 35.78 [ 2527 / 7063, 435 ins, 382 del, 1710 sub ]
%SER 58.31 [ 895 / 1535 ]
exp/mono/decode//wer_9
%WER 33.41 [ 2360 / 7063, 368 ins, 404 del, 1588 sub ]
%SER 54.59 [ 838 / 1535 ]

===== MONO ALIGNMENT =====

steps/align_si.sh --nj 4 --cmd run.pl data/train data/lang exp/mono exp/mono_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/mono, putting alignments in exp/mono_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/mono_ali
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== TRI1 (first triphone pass) TRAINING =====

steps/train_deltas.sh --cmd run.pl 2000 11000 data/train data/lang exp/mono_ali exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
WARNING (gmm-init-model[5.5.432~1-07c9d]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
** The warnings above about 'no stats' generally mean you have phones **
** (or groups of phones) in your phone set that had no corresponding data. **
** You should probably figure out whether something went wrong, **
** or whether your data just doesn't happen to have examples of those **
** phones. **
steps/train_deltas.sh: converting alignments from exp/mono_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri1
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log
1 warnings in exp/tri1/log/build_tree.log
117 warnings in exp/tri1/log/update.*.log
1 warnings in exp/tri1/log/questions.log
84 warnings in exp/tri1/log/init_model.log
10 warnings in exp/tri1/log/acc.*.*.log
15 warnings in exp/tri1/log/align.*.*.log
exp/tri1: nj=4 align prob=-90.76 over 1.47h [retry=0.0%, fail=0.0%] states=648 gauss=11027 tree-impr=3.89
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1

===== TRI1 (first triphone pass) DECODING =====

0 -0.0321367
[info]: CLG not stochastic.
0.573664 -0.0924099
HCLGa is not stochastic
steps/decode.sh --config conf/decode.config --nj 4 --cmd run.pl exp/tri1/graph data/test exp/tri1/decode
decode.sh: feature type is delta
steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri1/graph exp/tri1/decode
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,5,64) and mean=24.9
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode/log/analyze_lattice_depth_stats.log
exp/tri1/decode/wer_10
%WER 40.79 [ 2881 / 7063, 478 ins, 394 del, 2009 sub ]
%SER 62.93 [ 966 / 1535 ]
exp/tri1/decode/wer_11
%WER 37.49 [ 2648 / 7063, 384 ins, 434 del, 1830 sub ]
%SER 59.35 [ 911 / 1535 ]
exp/tri1/decode/wer_12
%WER 34.79 [ 2457 / 7063, 325 ins, 473 del, 1659 sub ]
%SER 56.22 [ 863 / 1535 ]
exp/tri1/decode/wer_13
%WER 33.16 [ 2342 / 7063, 287 ins, 508 del, 1547 sub ]
%SER 53.81 [ 826 / 1535 ]
exp/tri1/decode/wer_14
%WER 31.59 [ 2231 / 7063, 239 ins, 543 del, 1449 sub ]
%SER 52.12 [ 800 / 1535 ]
exp/tri1/decode/wer_15
%WER 30.54 [ 2157 / 7063, 210 ins, 573 del, 1374 sub ]
%SER 50.62 [ 777 / 1535 ]
exp/tri1/decode/wer_16
%WER 29.52 [ 2085 / 7063, 190 ins, 588 del, 1307 sub ]
%SER 49.12 [ 754 / 1535 ]
exp/tri1/decode/wer_17
%WER 28.97 [ 2046 / 7063, 169 ins, 602 del, 1275 sub ]
%SER 48.27 [ 741 / 1535 ]
exp/tri1/decode/wer_7
%WER 52.87 [ 3734 / 7063, 857 ins, 283 del, 2594 sub ]
%SER 74.14 [ 1138 / 1535 ]
exp/tri1/decode/wer_8
%WER 49.33 [ 3484 / 7063, 725 ins, 322 del, 2437 sub ]
%SER 71.01 [ 1090 / 1535 ]
exp/tri1/decode/wer_9
%WER 44.51 [ 3144 / 7063, 584 ins, 361 del, 2199 sub ]
%SER 66.71 [ 1024 / 1535 ]
exp/tri1/decode/wer_10
%WER 40.79 [ 2881 / 7063, 478 ins, 394 del, 2009 sub ]
%SER 62.93 [ 966 / 1535 ]
exp/tri1/decode/wer_11
%WER 37.49 [ 2648 / 7063, 384 ins, 434 del, 1830 sub ]
%SER 59.35 [ 911 / 1535 ]
exp/tri1/decode/wer_12
%WER 34.79 [ 2457 / 7063, 325 ins, 473 del, 1659 sub ]
%SER 56.22 [ 863 / 1535 ]
exp/tri1/decode/wer_13
%WER 33.16 [ 2342 / 7063, 287 ins, 508 del, 1547 sub ]
%SER 53.81 [ 826 / 1535 ]
exp/tri1/decode/wer_14
%WER 31.59 [ 2231 / 7063, 239 ins, 543 del, 1449 sub ]
%SER 52.12 [ 800 / 1535 ]
exp/tri1/decode/wer_15
%WER 30.54 [ 2157 / 7063, 210 ins, 573 del, 1374 sub ]
%SER 50.62 [ 777 / 1535 ]
exp/tri1/decode/wer_16
%WER 29.52 [ 2085 / 7063, 190 ins, 588 del, 1307 sub ]
%SER 49.12 [ 754 / 1535 ]
exp/tri1/decode/wer_17
%WER 28.97 [ 2046 / 7063, 169 ins, 602 del, 1275 sub ]
%SER 48.27 [ 741 / 1535 ]
exp/tri1/decode/wer_7
%WER 52.87 [ 3734 / 7063, 857 ins, 283 del, 2594 sub ]
%SER 74.14 [ 1138 / 1535 ]
exp/tri1/decode/wer_8
%WER 49.33 [ 3484 / 7063, 725 ins, 322 del, 2437 sub ]
%SER 71.01 [ 1090 / 1535 ]
exp/tri1/decode/wer_9
%WER 44.51 [ 3144 / 7063, 584 ins, 361 del, 2199 sub ]
%SER 66.71 [ 1024 / 1535 ]

===== run.sh script is finished =====

